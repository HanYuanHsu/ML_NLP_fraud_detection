{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed580d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library needed\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "import pickle\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263237b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(dat,train_dat):\n",
    "    \n",
    "    ### SALARY PROCESSING \n",
    "    # see if character is in text\n",
    "    def alpha_in_text(text):\n",
    "        return(any(c.isalpha() for c in text))\n",
    "\n",
    "    # see how many dashes are in text\n",
    "    def number_of_dashes(text):\n",
    "        return(sum([1 for i in text if '-' in i]))\n",
    "\n",
    "    # extract smallest salary range value\n",
    "    def salary_extract_first(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[0].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[0]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # largest salary range value\n",
    "    def salary_extract_second(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[1].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[1]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # convert numeric salary to category\n",
    "    def salary_category_first(number):\n",
    "        percentile = [60.0, 14000.0, 20000.0, 30000.0, 35000.0, 44374.4, 55000.0, 70000.0, 90000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "\n",
    "\n",
    "\n",
    "    def salary_category_second(number):\n",
    "        percentile = [120, 20000.0, 30000.0, 40000.0, 50000.0, 65000.0, 80000.0, 100000.0, 130000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "    \n",
    "    \n",
    "    ### ONE HOT ENCODING (training)\n",
    "    employment_type_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['employment_type']].fillna('NaN'))\n",
    "    required_experience_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_experience']].fillna('NaN'))\n",
    "    required_education_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_education']].fillna('NaN'))\n",
    "    industry_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['industry']].fillna('NaN'))\n",
    "    function_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['function.']].fillna('NaN'))\n",
    "    category_1 = train_dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = train_dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    salary_1_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_1))\n",
    "    salary_2_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_2))\n",
    "    profile_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['company_profile'].fillna('NaN'))\n",
    "    description_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['description'].fillna('NaN'))\n",
    "    requirements_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['requirements'].fillna('NaN'))\n",
    "    benefits_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['benefits'].fillna('NaN'))\n",
    "    \n",
    "    # transforming to one hot encoding\n",
    "    profile_transformed = pd.DataFrame.sparse.from_spmatrix(profile_onehot.transform(dat['company_profile'].fillna('NaN')))\n",
    "    description_transformed = pd.DataFrame.sparse.from_spmatrix(description_onehot.transform(dat['description'].fillna('NaN')))\n",
    "    requirements_transformed = pd.DataFrame.sparse.from_spmatrix(requirements_onehot.transform(dat['required_education'].fillna('NaN')))\n",
    "    benefits_transformed = pd.DataFrame.sparse.from_spmatrix(benefits_onehot.transform(dat['benefits'].fillna('NaN')))\n",
    "    \n",
    "    names = [['profile.'+ words for words in profile_onehot.get_feature_names()],\n",
    "            ['description.'+ words for words in description_onehot.get_feature_names()],\n",
    "            ['requirements.'+ words for words in requirements_onehot.get_feature_names()],\n",
    "            ['benefits.'+ words for words in benefits_onehot.get_feature_names()]]\n",
    "    \n",
    "    descriptive = pd.concat([profile_transformed,description_transformed,requirements_transformed,benefits_transformed],axis=1,ignore_index=True)\n",
    "    descriptive.columns = [item for sublist in names for item in sublist]\n",
    "    \n",
    "    ### OTHER PARSING\n",
    "    nacols = dat.isna()[['title', 'location', 'department', 'salary_range','description', 'requirements', 'benefits',\n",
    "                      'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
    "                      'required_experience', 'required_education', 'industry', 'function.']].astype('int')\n",
    "    \n",
    "    numeric_cols = dat[['telecommuting', 'has_company_logo', 'has_questions']]\n",
    "    # func to count words in document\n",
    "    document_word_count = lambda document: len(document.split(' '))\n",
    "    \n",
    "    # count words in column\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    df = copy.deepcopy(dat[columns])\n",
    "    for column in columns:\n",
    "            df[(str(column) + \"_length\")] = dat[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    \n",
    "    \n",
    "    # salary column one hot\n",
    "    category_1 = dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    \n",
    "    salary_1_transform = pd.DataFrame.sparse.from_spmatrix(salary_1_onehot.transform(pd.DataFrame(category_1)))\n",
    "    salary_2_transform = pd.DataFrame.sparse.from_spmatrix(salary_2_onehot.transform(pd.DataFrame(category_2)))\n",
    "    \n",
    "    # transform to one hot\n",
    "    employment_type_transformed =  pd.DataFrame.sparse.from_spmatrix(employment_type_onehot.transform(dat[['employment_type']].fillna('NaN')))\n",
    "    required_experience_transformed =  pd.DataFrame.sparse.from_spmatrix(required_experience_onehot.transform(dat[['required_experience']].fillna('NaN')))\n",
    "    required_education_transformed =  pd.DataFrame.sparse.from_spmatrix(required_education_onehot.transform(dat[['required_education']].fillna('NaN')))\n",
    "    industry_transformed =  pd.DataFrame.sparse.from_spmatrix(industry_onehot.transform(dat[['industry']].fillna('NaN')))\n",
    "    function_transformed =  pd.DataFrame.sparse.from_spmatrix(function_onehot.transform(dat[['function.']].fillna('NaN')))\n",
    "    \n",
    "    \n",
    "    return(pd.concat([nacols,salary_1_transform, salary_2_transform,df.iloc[:,4:],\n",
    "                      employment_type_transformed, required_experience_transformed, required_education_transformed, industry_transformed,function_transformed,numeric_cols,\n",
    "                     descriptive],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a7ce54",
   "metadata": {},
   "source": [
    "# 1. import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ce13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SelectKBest from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('Final Random Forest Model.pkl', 'rb') as inp:\n",
    "    pipe = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df190124",
   "metadata": {},
   "source": [
    "# 2. import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6465bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_train = pd.read_csv(\"job_training_data.csv\")\n",
    "dat_test = pd.read_csv(\"job_verification_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5595ab0f",
   "metadata": {},
   "source": [
    "# 3. parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78618d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data_test = parsing(dat_test,dat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa08e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>...</th>\n",
       "      <th>benefits.zodat</th>\n",
       "      <th>benefits.zollman</th>\n",
       "      <th>benefits.zomato</th>\n",
       "      <th>benefits.zone</th>\n",
       "      <th>benefits.zones</th>\n",
       "      <th>benefits.zoning</th>\n",
       "      <th>benefits.zowel</th>\n",
       "      <th>benefits.zu</th>\n",
       "      <th>benefits.zult</th>\n",
       "      <th>benefits.zutrifft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 75360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title  location  department  salary_range  description  requirements  \\\n",
       "0        0         0           1             1            0             0   \n",
       "1        0         0           0             1            0             0   \n",
       "2        0         0           1             0            0             1   \n",
       "3        0         0           1             1            0             1   \n",
       "4        0         0           1             1            0             0   \n",
       "..     ...       ...         ...           ...          ...           ...   \n",
       "995      0         0           1             1            0             0   \n",
       "996      0         0           1             1            0             0   \n",
       "997      0         0           0             1            0             0   \n",
       "998      0         0           1             1            0             0   \n",
       "999      0         0           1             1            0             0   \n",
       "\n",
       "     benefits  telecommuting  has_company_logo  has_questions  ...  \\\n",
       "0           0              0                 0              0  ...   \n",
       "1           0              0                 0              0  ...   \n",
       "2           0              0                 0              0  ...   \n",
       "3           1              0                 0              0  ...   \n",
       "4           0              0                 0              0  ...   \n",
       "..        ...            ...               ...            ...  ...   \n",
       "995         1              0                 0              0  ...   \n",
       "996         1              0                 0              0  ...   \n",
       "997         0              0                 0              0  ...   \n",
       "998         1              0                 0              0  ...   \n",
       "999         0              0                 0              0  ...   \n",
       "\n",
       "     benefits.zodat  benefits.zollman  benefits.zomato  benefits.zone  \\\n",
       "0               0.0               0.0              0.0            0.0   \n",
       "1               0.0               0.0              0.0            0.0   \n",
       "2               0.0               0.0              0.0            0.0   \n",
       "3               0.0               0.0              0.0            0.0   \n",
       "4               0.0               0.0              0.0            0.0   \n",
       "..              ...               ...              ...            ...   \n",
       "995             0.0               0.0              0.0            0.0   \n",
       "996             0.0               0.0              0.0            0.0   \n",
       "997             0.0               0.0              0.0            0.0   \n",
       "998             0.0               0.0              0.0            0.0   \n",
       "999             0.0               0.0              0.0            0.0   \n",
       "\n",
       "     benefits.zones  benefits.zoning  benefits.zowel  benefits.zu  \\\n",
       "0               0.0              0.0             0.0          0.0   \n",
       "1               0.0              0.0             0.0          0.0   \n",
       "2               0.0              0.0             0.0          0.0   \n",
       "3               0.0              0.0             0.0          0.0   \n",
       "4               0.0              0.0             0.0          0.0   \n",
       "..              ...              ...             ...          ...   \n",
       "995             0.0              0.0             0.0          0.0   \n",
       "996             0.0              0.0             0.0          0.0   \n",
       "997             0.0              0.0             0.0          0.0   \n",
       "998             0.0              0.0             0.0          0.0   \n",
       "999             0.0              0.0             0.0          0.0   \n",
       "\n",
       "     benefits.zult  benefits.zutrifft  \n",
       "0              0.0                0.0  \n",
       "1              0.0                0.0  \n",
       "2              0.0                0.0  \n",
       "3              0.0                0.0  \n",
       "4              0.0                0.0  \n",
       "..             ...                ...  \n",
       "995            0.0                0.0  \n",
       "996            0.0                0.0  \n",
       "997            0.0                0.0  \n",
       "998            0.0                0.0  \n",
       "999            0.0                0.0  \n",
       "\n",
       "[1000 rows x 75360 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c05eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test\n",
    "y_test = dat_test.fraudulent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f38f86",
   "metadata": {},
   "source": [
    "# 4. classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc92514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a0306\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:624: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[932,  18],\n",
       "       [ 10,  40]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test,pipe.predict_proba(X_test)[:,1]>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e0f2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pipe.predict_proba(X_test)[:,1]>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d42e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,pipe.predict_proba(X_test)[:,1]>0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
