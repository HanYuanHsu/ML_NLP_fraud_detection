{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d43e30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yunjaecho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools \n",
    "import os\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk.corpus # sample text for performing tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9fa5f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sean's parsing function\n",
    "\n",
    "def parsing(dat,train_dat):\n",
    "    \n",
    "    ### SALARY PROCESSING \n",
    "    # see if character is in text\n",
    "    def alpha_in_text(text):\n",
    "        return(any(c.isalpha() for c in text))\n",
    "\n",
    "    # see how many dashes are in text\n",
    "    def number_of_dashes(text):\n",
    "        return(sum([1 for i in text if '-' in i]))\n",
    "\n",
    "    # extract smallest salary range value\n",
    "    def salary_extract_first(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[0].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[0]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # largest salary range value\n",
    "    def salary_extract_second(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[1].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[1]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # convert numeric salary to category\n",
    "    def salary_category_first(number):\n",
    "        percentile = [60.0, 14000.0, 20000.0, 30000.0, 35000.0, 44374.4, 55000.0, 70000.0, 90000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "\n",
    "\n",
    "\n",
    "    def salary_category_second(number):\n",
    "        percentile = [120, 20000.0, 30000.0, 40000.0, 50000.0, 65000.0, 80000.0, 100000.0, 130000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "    \n",
    "    \n",
    "    ### ONE HOT ENCODING (training)\n",
    "    employment_type_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['employment_type']].fillna('NaN'))\n",
    "    required_experience_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_experience']].fillna('NaN'))\n",
    "    required_education_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_education']].fillna('NaN'))\n",
    "    industry_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['industry']].fillna('NaN'))\n",
    "    function_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['function.']].fillna('NaN'))\n",
    "    category_1 = train_dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = train_dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    salary_1_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_1))\n",
    "    salary_2_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_2))\n",
    "    \n",
    "    ### OTHER PARSING\n",
    "    nacols = dat.isna()[['title', 'location', 'department', 'salary_range','description', 'requirements', 'benefits',\n",
    "                      'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
    "                      'required_experience', 'required_education', 'industry', 'function.']].astype('int')\n",
    "    \n",
    "    numeric_cols = dat[['telecommuting', 'has_company_logo', 'has_questions']]\n",
    "    # func to count words in document\n",
    "    document_word_count = lambda document: len(document.split(' '))\n",
    "    \n",
    "    # count words in column\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    df = copy.deepcopy(dat[columns])\n",
    "    for column in columns:\n",
    "            df[(str(column) + \"_length\")] = dat[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    \n",
    "    \n",
    "    # salary column one hot\n",
    "    category_1 = dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    \n",
    "    salary_1_transform = pd.DataFrame.sparse.from_spmatrix(salary_1_onehot.transform(pd.DataFrame(category_1)))\n",
    "    salary_2_transform = pd.DataFrame.sparse.from_spmatrix(salary_2_onehot.transform(pd.DataFrame(category_2)))\n",
    "    \n",
    "    # transform to one hot\n",
    "    employment_type_transformed =  pd.DataFrame.sparse.from_spmatrix(employment_type_onehot.transform(dat[['employment_type']].fillna('NaN')))\n",
    "    required_experience_transformed =  pd.DataFrame.sparse.from_spmatrix(required_experience_onehot.transform(dat[['required_experience']].fillna('NaN')))\n",
    "    required_education_transformed =  pd.DataFrame.sparse.from_spmatrix(required_education_onehot.transform(dat[['required_education']].fillna('NaN')))\n",
    "    industry_transformed =  pd.DataFrame.sparse.from_spmatrix(industry_onehot.transform(dat[['industry']].fillna('NaN')))\n",
    "    function_transformed =  pd.DataFrame.sparse.from_spmatrix(function_onehot.transform(dat[['function.']].fillna('NaN')))\n",
    "    \n",
    "    \n",
    "    return(pd.concat([nacols,salary_1_transform, salary_2_transform,df.iloc[:,4:],\n",
    "                      employment_type_transformed, required_experience_transformed, required_education_transformed, industry_transformed,function_transformed,numeric_cols],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6a29f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_train = pd.read_csv(\"job_training_data.csv\")\n",
    "dat_train2 = pd.read_csv(\"practice_job_verification_data.csv\")\n",
    "X1 = parsing(dat_train,dat_train)\n",
    "X2 = parsing(dat_train2,dat_train)\n",
    "y1 = dat_train[\"fraudulent\"]\n",
    "y2 = dat_train2[\"fraudulent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d0ac3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_counter(df,columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]):\n",
    "    length = []\n",
    "    for column in columns:\n",
    "        df[(str(column) + \"_length\")] = df[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e77abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(\"job_training_data.csv\")\n",
    "jobs = length_counter(jobs)\n",
    "nf_jobs = jobs[jobs[\"fraudulent\"] == 0]\n",
    "f_jobs = jobs[jobs[\"fraudulent\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5331a",
   "metadata": {},
   "source": [
    "# frequency selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d561ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \n",
    "    \".\",\n",
    "    'a',\n",
    " 'about',\n",
    " 'above',\n",
    " 'after',\n",
    " 'again',\n",
    " 'against',\n",
    " 'ain',\n",
    " 'all',\n",
    " 'am',\n",
    " 'an',\n",
    " 'and',\n",
    " 'any',\n",
    " 'are',\n",
    " 'aren',\n",
    " \"aren't\",\n",
    " 'as',\n",
    " 'at',\n",
    " 'be',\n",
    " 'because',\n",
    " 'been',\n",
    " 'before',\n",
    " 'being',\n",
    " 'below',\n",
    " 'between',\n",
    " 'both',\n",
    " 'but',\n",
    " 'by',\n",
    " 'can',\n",
    " 'couldn',\n",
    " \"couldn't\",\n",
    " 'd',\n",
    " 'did',\n",
    " 'didn',\n",
    " \"didn't\",\n",
    " 'do',\n",
    " 'does',\n",
    " 'doesn',\n",
    " \"doesn't\",\n",
    " 'doing',\n",
    " 'don',\n",
    " \"don't\",\n",
    " 'down',\n",
    " 'during',\n",
    " 'each',\n",
    " 'few',\n",
    " 'for',\n",
    " 'from',\n",
    " 'further',\n",
    " 'had',\n",
    " 'hadn',\n",
    " \"hadn't\",\n",
    " 'has',\n",
    " 'hasn',\n",
    " \"hasn't\",\n",
    " 'have',\n",
    " 'haven',\n",
    " \"haven't\",\n",
    " 'having',\n",
    " 'he',\n",
    " 'her',\n",
    " 'here',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'him',\n",
    " 'himself',\n",
    " 'his',\n",
    " 'how',\n",
    " 'i',\n",
    " 'if',\n",
    " 'in',\n",
    " 'into',\n",
    " 'is',\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'it',\n",
    " \"it's\",\n",
    " 'its',\n",
    " 'itself',\n",
    " 'just',\n",
    " 'll',\n",
    " 'm',\n",
    " 'ma',\n",
    " 'me',\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'more',\n",
    " 'most',\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'my',\n",
    " 'myself',\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'now',\n",
    " 'o',\n",
    " 'of',\n",
    " 'off',\n",
    " 'on',\n",
    " 'once',\n",
    " 'only',\n",
    " 'or',\n",
    " 'other',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'out',\n",
    " 'over',\n",
    " 'own',\n",
    " 're',\n",
    " 's',\n",
    " 'same',\n",
    " 'shan',\n",
    " \"shan't\",\n",
    " 'she',\n",
    " \"she's\",\n",
    " 'should',\n",
    " \"should've\",\n",
    " 'shouldn',\n",
    " \"shouldn't\",\n",
    " 'so',\n",
    " 'some',\n",
    " 'such',\n",
    " 't',\n",
    " 'than',\n",
    " 'that',\n",
    " \"that'll\",\n",
    " 'the',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'them',\n",
    " 'themselves',\n",
    " 'then',\n",
    " 'there',\n",
    " 'these',\n",
    " 'they',\n",
    " 'this',\n",
    " 'those',\n",
    " 'through',\n",
    " 'to',\n",
    " 'too',\n",
    " 'under',\n",
    " 'until',\n",
    " 'up',\n",
    " 've',\n",
    " 'very',\n",
    " 'was',\n",
    " 'wasn',\n",
    " \"wasn't\",\n",
    " 'we',\n",
    " 'were',\n",
    " 'weren',\n",
    " \"weren't\",\n",
    " 'what',\n",
    " 'when',\n",
    " 'where',\n",
    " 'which',\n",
    " 'while',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'why',\n",
    " 'will',\n",
    " 'with',\n",
    " 'won',\n",
    " \"won't\",\n",
    " 'wouldn',\n",
    " \"wouldn't\",\n",
    " 'y',\n",
    " 'you',\n",
    " \"you'd\",\n",
    " \"you'll\",\n",
    " \"you're\",\n",
    " \"you've\",\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\"us\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8cfeb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strips(x):\n",
    "    return (x.strip().strip(\"'\").strip('\"').strip(\",\").strip(\"(\").strip(\")\").strip(\".\").strip(\";\").strip(\":\"))\n",
    "\n",
    "def merge_and_tokenize(df,column = \"company_profile\",k = 0):\n",
    "    merged_text = []\n",
    "    text_dict = {}\n",
    "    parsed_row = []\n",
    "    for sentence in df[column]:\n",
    "        if sentence == sentence:\n",
    "            words = sentence.lower().split()\n",
    "            words = [strips(w) for w in words if strips(w) not in stop_words]\n",
    "            for word in words: # remove stop words\n",
    "                if \"url\" in str(word):\n",
    "                    words.remove(word)\n",
    "\n",
    "            parsed_row.append(words)\n",
    "            merged_text.extend(words)\n",
    "        else:\n",
    "            parsed_row.append(np.nan)\n",
    "            \n",
    "    fdist = FreqDist(merged_text)\n",
    "    \n",
    "    keys = list(fdist.keys())\n",
    "    \n",
    "    for key in keys:\n",
    "        if fdist[key] <= k:\n",
    "            del fdist[key]\n",
    "    total_counts = sum(fdist.values())\n",
    "    for key in fdist:\n",
    "        fdist[key] = [fdist[key],fdist[key]/total_counts]\n",
    "    return fdist,parsed_row\n",
    "\n",
    "def fraud_frequency(fraud_dict,parsed_rows):\n",
    "    freq_list = []\n",
    "    \n",
    "    for text in tqdm(parsed_rows):\n",
    "        parsed_dict = {key:0 for key in fraud_dict.keys()}\n",
    "        if text == text:\n",
    "            for word in text:\n",
    "                if word in parsed_dict:\n",
    "                    parsed_dict[word] += 1/len(text)\n",
    "        else:\n",
    "            freq_list.append(parsed_dict)\n",
    "            continue\n",
    "        \n",
    "        freq_list.append(parsed_dict)\n",
    "        \n",
    "    return pd.DataFrame(freq_list)\n",
    "\n",
    "def fraud_freq_dictionary(fraud_dict,nfraud_dict, th_percentage = 0.2,tops = 5):\n",
    "    differenced_farud = {}\n",
    "    for key in fraud_dict.keys():\n",
    "        if key in nfraud_dict.keys():\n",
    "            if abs(fraud_dict[key][1] - nfraud_dict[key][1]) >= fraud_dict[key][1]*th_percentage:\n",
    "                differenced_farud[key] = fraud_dict[key]\n",
    "        if key not in nfraud_dict.keys():\n",
    "            differenced_farud[key] = fraud_dict[key]\n",
    "                   \n",
    "    sorted_differenced_fraud = sorted(differenced_farud.items(), key=operator.itemgetter(1),reverse = True)\n",
    "    #out = dict(itertools.islice(sorted_differenced_farud.items(), tops)) \n",
    "    out = dict(sorted_differenced_fraud[:tops])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fc4d2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_freq_generator(train,test,column,th_percentage,th_count,tops,train_parsing = True):\n",
    "    if train_parsing:\n",
    "        _,parsed_rows = merge_and_tokenize(train,column,th_count*5)\n",
    "        fraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 1],column ,th_count)\n",
    "        nfraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 0],column ,th_count*5)\n",
    "        filtered_fraud_dict = fraud_freq_dictionary(fraud_dict,nfraud_dict,th_percentage,tops)\n",
    "        fraud_freq = fraud_frequency(filtered_fraud_dict,parsed_rows)\n",
    "    else:\n",
    "        _,parsed_rows = merge_and_tokenize(test,column,th_count*5)\n",
    "        fraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 1],column ,th_count)\n",
    "        nfraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 0],column ,th_count*5)\n",
    "        filtered_fraud_dict = fraud_freq_dictionary(fraud_dict,nfraud_dict,th_percentage,tops)\n",
    "        fraud_freq = fraud_frequency(filtered_fraud_dict,parsed_rows)\n",
    "    \n",
    "    return fraud_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a5ea12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"job_training_data.csv\")\n",
    "test_data = pd.read_csv(\"job_verification_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "8e33490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function.</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4859</td>\n",
       "      <td>PR8 Apprentice Administrator Under NAS 16-18 Y...</td>\n",
       "      <td>GB, , Southport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Established on the principles that full time e...</td>\n",
       "      <td>Government funding is only available for 16-18...</td>\n",
       "      <td>16-18 year olds only due to government funding...</td>\n",
       "      <td>Career prospects.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Administrative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9391</td>\n",
       "      <td>Freelance Editors (m/f) for Russian Courses fo...</td>\n",
       "      <td>DE, BE, Berlin</td>\n",
       "      <td>Didactics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babbel enables anyone to learn languages in an...</td>\n",
       "      <td>We are looking for German native speakers (m/f...</td>\n",
       "      <td>Experience as an editor or proofreaderPreferab...</td>\n",
       "      <td>Flexible work schedulesMost work done from hom...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E-Learning</td>\n",
       "      <td>Writing/Editing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8074</td>\n",
       "      <td>Entry Level Sales</td>\n",
       "      <td>US, NC, Raleigh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000-75000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Summary: Achieves maximum sales profit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great Health and DentalFast Advancement Opport...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3739</td>\n",
       "      <td>Android Developer</td>\n",
       "      <td>GB, LND, London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Money is a person-to-person money transfer app...</td>\n",
       "      <td>A great opportunity to be a part of a growing ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5616</td>\n",
       "      <td>Software Engineer (Ruby)</td>\n",
       "      <td>US, MA, 02139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cogo Labs is the technology-driven incubator o...</td>\n",
       "      <td>It can be hard to say what sets one workplace ...</td>\n",
       "      <td>You should be comfortable with most of these t...</td>\n",
       "      <td>More about Cogo Labs:We are a 100% Mac/Linux s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>213</td>\n",
       "      <td>Customer Service Associate</td>\n",
       "      <td>US, IN, Indianapolis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novitex Enterprise Solutions, formerly Pitney ...</td>\n",
       "      <td>The Customer Service Associate will be based i...</td>\n",
       "      <td>Minimum Requirements:Minimum of 1 year of cust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>11278</td>\n",
       "      <td>Commercial Real Estate Salesperson - NJ</td>\n",
       "      <td>US, NJ, Elmwood Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With over 1,300 investment professionals locat...</td>\n",
       "      <td>Marcus &amp;amp; Millichap (NYSE: MMI) is the larg...</td>\n",
       "      <td>Bachelor's or Associate Degree Excellent Oral ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate Degree</td>\n",
       "      <td>Commercial Real Estate</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>858</td>\n",
       "      <td>Sales Associate Germany</td>\n",
       "      <td>DE, BE, Berlin</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EventMobi is changing the way attendees experi...</td>\n",
       "      <td>As a Sales Associate at EventMobi, you will wo...</td>\n",
       "      <td>Have 2-4 years of sales experience, preferrabe...</td>\n",
       "      <td>An experience of a life-time working with youn...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Events Services</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>14065</td>\n",
       "      <td>Delivery Driver - Part Time</td>\n",
       "      <td>US, WA, Redmond</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novitex Enterprise Solutions, formerly Pitney ...</td>\n",
       "      <td>We are currently seeking a Part Time Delivery ...</td>\n",
       "      <td>Required Qualifications:A valid driver's licen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>17720</td>\n",
       "      <td>CUSTOMER SERVICE REP</td>\n",
       "      <td>US, TX, DALLAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DescriptionJob Title: Customer Service Represe...</td>\n",
       "      <td>HIGH SCHOOL DIPLOMA</td>\n",
       "      <td>HEALTH,DENTAL INSURANCE , 401K , STOCK PLAN FO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id                                              title  \\\n",
       "0      4859  PR8 Apprentice Administrator Under NAS 16-18 Y...   \n",
       "1      9391  Freelance Editors (m/f) for Russian Courses fo...   \n",
       "2      8074                                  Entry Level Sales   \n",
       "3      3739                                  Android Developer   \n",
       "4      5616                           Software Engineer (Ruby)   \n",
       "..      ...                                                ...   \n",
       "995     213                       Customer Service Associate     \n",
       "996   11278            Commercial Real Estate Salesperson - NJ   \n",
       "997     858                            Sales Associate Germany   \n",
       "998   14065                       Delivery Driver - Part Time    \n",
       "999   17720                               CUSTOMER SERVICE REP   \n",
       "\n",
       "                 location department salary_range  \\\n",
       "0         GB, , Southport        NaN          NaN   \n",
       "1          DE, BE, Berlin  Didactics          NaN   \n",
       "2         US, NC, Raleigh        NaN  55000-75000   \n",
       "3         GB, LND, London        NaN          NaN   \n",
       "4           US, MA, 02139        NaN          NaN   \n",
       "..                    ...        ...          ...   \n",
       "995  US, IN, Indianapolis        NaN          NaN   \n",
       "996  US, NJ, Elmwood Park        NaN          NaN   \n",
       "997        DE, BE, Berlin      Sales          NaN   \n",
       "998       US, WA, Redmond        NaN          NaN   \n",
       "999        US, TX, DALLAS        NaN          NaN   \n",
       "\n",
       "                                       company_profile  \\\n",
       "0    Established on the principles that full time e...   \n",
       "1    Babbel enables anyone to learn languages in an...   \n",
       "2                                                  NaN   \n",
       "3    Money is a person-to-person money transfer app...   \n",
       "4    Cogo Labs is the technology-driven incubator o...   \n",
       "..                                                 ...   \n",
       "995  Novitex Enterprise Solutions, formerly Pitney ...   \n",
       "996  With over 1,300 investment professionals locat...   \n",
       "997  EventMobi is changing the way attendees experi...   \n",
       "998  Novitex Enterprise Solutions, formerly Pitney ...   \n",
       "999                                                NaN   \n",
       "\n",
       "                                           description  \\\n",
       "0    Government funding is only available for 16-18...   \n",
       "1    We are looking for German native speakers (m/f...   \n",
       "2    General Summary: Achieves maximum sales profit...   \n",
       "3    A great opportunity to be a part of a growing ...   \n",
       "4    It can be hard to say what sets one workplace ...   \n",
       "..                                                 ...   \n",
       "995  The Customer Service Associate will be based i...   \n",
       "996  Marcus &amp; Millichap (NYSE: MMI) is the larg...   \n",
       "997  As a Sales Associate at EventMobi, you will wo...   \n",
       "998  We are currently seeking a Part Time Delivery ...   \n",
       "999  DescriptionJob Title: Customer Service Represe...   \n",
       "\n",
       "                                          requirements  \\\n",
       "0    16-18 year olds only due to government funding...   \n",
       "1    Experience as an editor or proofreaderPreferab...   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    You should be comfortable with most of these t...   \n",
       "..                                                 ...   \n",
       "995  Minimum Requirements:Minimum of 1 year of cust...   \n",
       "996  Bachelor's or Associate Degree Excellent Oral ...   \n",
       "997  Have 2-4 years of sales experience, preferrabe...   \n",
       "998  Required Qualifications:A valid driver's licen...   \n",
       "999                                HIGH SCHOOL DIPLOMA   \n",
       "\n",
       "                                              benefits  telecommuting  \\\n",
       "0                                    Career prospects.              0   \n",
       "1    Flexible work schedulesMost work done from hom...              0   \n",
       "2    Great Health and DentalFast Advancement Opport...              0   \n",
       "3                                                  NaN              0   \n",
       "4    More about Cogo Labs:We are a 100% Mac/Linux s...              0   \n",
       "..                                                 ...            ...   \n",
       "995                                                NaN              0   \n",
       "996                                                NaN              0   \n",
       "997  An experience of a life-time working with youn...              0   \n",
       "998                                                NaN              0   \n",
       "999  HEALTH,DENTAL INSURANCE , 401K , STOCK PLAN FO...              0   \n",
       "\n",
       "     has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                   1              1       Full-time      Not Applicable   \n",
       "1                   1              1           Other                 NaN   \n",
       "2                   0              0       Full-time         Entry level   \n",
       "3                   1              0       Full-time                 NaN   \n",
       "4                   1              1             NaN                 NaN   \n",
       "..                ...            ...             ...                 ...   \n",
       "995                 1              0       Full-time         Entry level   \n",
       "996                 1              1       Full-time           Associate   \n",
       "997                 1              1       Full-time           Associate   \n",
       "998                 1              0       Full-time         Entry level   \n",
       "999                 0              0       Full-time           Associate   \n",
       "\n",
       "            required_education                industry         function.  \\\n",
       "0    High School or equivalent                     NaN    Administrative   \n",
       "1                          NaN              E-Learning   Writing/Editing   \n",
       "2    High School or equivalent      Financial Services             Sales   \n",
       "3                          NaN                     NaN               NaN   \n",
       "4                          NaN                     NaN               NaN   \n",
       "..                         ...                     ...               ...   \n",
       "995  High School or equivalent       Consumer Services  Customer Service   \n",
       "996           Associate Degree  Commercial Real Estate             Sales   \n",
       "997                        NaN         Events Services             Sales   \n",
       "998  High School or equivalent       Computer Software  Customer Service   \n",
       "999  High School or equivalent       Consumer Services  Customer Service   \n",
       "\n",
       "     fraudulent  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "..          ...  \n",
       "995           0  \n",
       "996           0  \n",
       "997           0  \n",
       "998           0  \n",
       "999           1  \n",
       "\n",
       "[1000 rows x 18 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "e9b0144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 181824.38it/s]\n",
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 162435.60it/s]\n",
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 195795.53it/s]\n",
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 479129.47it/s]\n"
     ]
    }
   ],
   "source": [
    "company_freq = fraud_freq_generator(train_data,test_data,\"company_profile\",th_percentage = 0.25, th_count = 15, tops = 10)\n",
    "description_freq = fraud_freq_generator(train_data,test_data,\"description\",th_percentage = 0.25, th_count = 15, tops = 10)\n",
    "requirements_freq = fraud_freq_generator(train_data,test_data,\"requirements\",th_percentage = 0.25,th_count = 15, tops = 10)\n",
    "benefits_freq = fraud_freq_generator(train_data,test_data,\"benefits\",th_percentage = 0.25, th_count = 15, tops = 10)\n",
    "\n",
    "big_matrix = pd.concat([company_freq,description_freq,requirements_freq,benefits_freq],axis=1)\n",
    "big_matrix[\"fraudulent\"] = train_data[\"fraudulent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4b44ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1449   94]\n",
      " [  31   35]]\n",
      "0.9223119950279677\n",
      "0.5303030303030303\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = big_matrix\n",
    "\n",
    "\n",
    "X = feature_matrix.drop(\"fraudulent\", axis = 1)\n",
    "y = feature_matrix.fraudulent\n",
    "y = y.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state =999999999)\n",
    "rfm = RandomForestClassifier()\n",
    "rfm = RandomForestClassifier(n_estimators = 200, max_features=None ,oob_score=True,n_jobs=6)\n",
    "rfm.fit(X_train,y_train)\n",
    "#y_pred_rfm=rfm.predict(X_test)\n",
    "y_pred_rfm = (rfm.predict_proba(X_test)[:, 1] > 0.15).astype(int)\n",
    "print(confusion_matrix(y_test,y_pred_rfm))\n",
    "print(accuracy_score(y_test,y_pred_rfm))\n",
    "print(recall_score(y_test,y_pred_rfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b72539fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 236472.01it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 144342.49it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 237194.14it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 394758.02it/s]\n"
     ]
    }
   ],
   "source": [
    "company_freq2 = fraud_freq_generator(train_data,test_data,\"company_profile\",th_percentage = 0.25, th_count = 15, tops = 10,train_parsing =False)\n",
    "description_freq2 = fraud_freq_generator(train_data,test_data,\"description\",th_percentage = 0.25, th_count = 15, tops = 10,train_parsing =False)\n",
    "requirements_freq2 = fraud_freq_generator(train_data,test_data,\"requirements\",th_percentage = 0.25,th_count = 15, tops = 10,train_parsing =False)\n",
    "benefits_freq2 = fraud_freq_generator(train_data,test_data,\"benefits\",th_percentage = 0.25, th_count = 15, tops = 10,train_parsing = False)\n",
    "\n",
    "big_matrix2 = pd.concat([company_freq2,description_freq2,requirements_freq2,benefits_freq2],axis=1)\n",
    "big_matrix2[\"fraudulent\"] = test_data[\"fraudulent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "eab51e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>candidates</th>\n",
       "      <th>recruiting</th>\n",
       "      <th>bonus</th>\n",
       "      <th>solutions</th>\n",
       "      <th>experience</th>\n",
       "      <th>products</th>\n",
       "      <th>financing</th>\n",
       "      <th>signing</th>\n",
       "      <th>referral</th>\n",
       "      <th>...</th>\n",
       "      <th>training</th>\n",
       "      <th>environment</th>\n",
       "      <th>time</th>\n",
       "      <th>working</th>\n",
       "      <th>full</th>\n",
       "      <th>+</th>\n",
       "      <th>please</th>\n",
       "      <th>skills</th>\n",
       "      <th>compensation</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     business  candidates  recruiting  bonus  solutions  experience  products  \\\n",
       "0    0.000000         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "1    0.000000         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "2    0.000000         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "3    0.000000         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "4    0.041667         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "..        ...         ...         ...    ...        ...         ...       ...   \n",
       "995  0.031250         0.0         0.0    0.0   0.046875    0.000000       0.0   \n",
       "996  0.000000         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "997  0.000000         0.0         0.0    0.0   0.000000    0.030303       0.0   \n",
       "998  0.031250         0.0         0.0    0.0   0.046875    0.000000       0.0   \n",
       "999  0.000000         0.0         0.0    0.0   0.000000    0.000000       0.0   \n",
       "\n",
       "     financing  signing  referral  ...  training  environment  time   working  \\\n",
       "0     0.000000      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "1     0.000000      0.0       0.0  ...   0.04878     0.000000   0.0  0.000000   \n",
       "2     0.000000      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "3     0.000000      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "4     0.000000      0.0       0.0  ...   0.00000     0.022727   0.0  0.000000   \n",
       "..         ...      ...       ...  ...       ...          ...   ...       ...   \n",
       "995   0.000000      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "996   0.019802      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "997   0.000000      0.0       0.0  ...   0.00000     0.018868   0.0  0.018868   \n",
       "998   0.000000      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "999   0.000000      0.0       0.0  ...   0.00000     0.000000   0.0  0.000000   \n",
       "\n",
       "     full    +  please  skills  compensation  fraudulent  \n",
       "0     0.0  0.0     0.0     0.0           0.0           0  \n",
       "1     0.0  0.0     0.0     0.0           0.0           0  \n",
       "2     0.0  0.0     0.0     0.0           0.0           0  \n",
       "3     0.0  0.0     0.0     0.0           0.0           0  \n",
       "4     0.0  0.0     0.0     0.0           0.0           0  \n",
       "..    ...  ...     ...     ...           ...         ...  \n",
       "995   0.0  0.0     0.0     0.0           0.0           0  \n",
       "996   0.0  0.0     0.0     0.0           0.0           0  \n",
       "997   0.0  0.0     0.0     0.0           0.0           0  \n",
       "998   0.0  0.0     0.0     0.0           0.0           0  \n",
       "999   0.0  0.0     0.0     0.0           0.0           1  \n",
       "\n",
       "[1000 rows x 41 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3c137b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[895  55]\n",
      " [ 19  31]]\n",
      "0.926\n",
      "0.62\n"
     ]
    }
   ],
   "source": [
    "train_matrix = big_matrix\n",
    "test_matrix = big_matrix2\n",
    "\n",
    "X_train = train_matrix.drop(\"fraudulent\", axis = 1)\n",
    "y_train = train_matrix.fraudulent.astype(int)\n",
    "\n",
    "X_test = test_matrix.drop(\"fraudulent\", axis = 1)\n",
    "y_test = test_matrix.fraudulent.astype(int)\n",
    "\n",
    "rfm = RandomForestClassifier()\n",
    "rfm = RandomForestClassifier(n_estimators = 200, max_features=None ,oob_score=True,n_jobs=6)\n",
    "rfm.fit(X_train,y_train)\n",
    "#y_pred_rfm=rfm.predict(X_test)\n",
    "y_pred_rfm = (rfm.predict_proba(X_test)[:, 1] > 0.13).astype(int)\n",
    "print(confusion_matrix(y_test,y_pred_rfm))\n",
    "print(accuracy_score(y_test,y_pred_rfm))\n",
    "print(recall_score(y_test,y_pred_rfm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
