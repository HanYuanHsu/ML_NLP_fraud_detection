{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d43e30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yunjaecho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools \n",
    "import os\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk.corpus # sample text for performing tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fa5f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sean's parsing function\n",
    "\n",
    "def parsing(dat,train_dat):\n",
    "    \n",
    "    ### SALARY PROCESSING \n",
    "    # see if character is in text\n",
    "    def alpha_in_text(text):\n",
    "        return(any(c.isalpha() for c in text))\n",
    "\n",
    "    # see how many dashes are in text\n",
    "    def number_of_dashes(text):\n",
    "        return(sum([1 for i in text if '-' in i]))\n",
    "\n",
    "    # extract smallest salary range value\n",
    "    def salary_extract_first(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[0].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[0]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # largest salary range value\n",
    "    def salary_extract_second(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[1].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[1]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # convert numeric salary to category\n",
    "    def salary_category_first(number):\n",
    "        percentile = [60.0, 14000.0, 20000.0, 30000.0, 35000.0, 44374.4, 55000.0, 70000.0, 90000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "\n",
    "\n",
    "\n",
    "    def salary_category_second(number):\n",
    "        percentile = [120, 20000.0, 30000.0, 40000.0, 50000.0, 65000.0, 80000.0, 100000.0, 130000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "    \n",
    "    \n",
    "    ### ONE HOT ENCODING (training)\n",
    "    employment_type_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['employment_type']].fillna('NaN'))\n",
    "    required_experience_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_experience']].fillna('NaN'))\n",
    "    required_education_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_education']].fillna('NaN'))\n",
    "    industry_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['industry']].fillna('NaN'))\n",
    "    function_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['function.']].fillna('NaN'))\n",
    "    category_1 = train_dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = train_dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    salary_1_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_1))\n",
    "    salary_2_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_2))\n",
    "    \n",
    "    ### OTHER PARSING\n",
    "    nacols = dat.isna()[['title', 'location', 'department', 'salary_range','description', 'requirements', 'benefits',\n",
    "                      'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
    "                      'required_experience', 'required_education', 'industry', 'function.']].astype('int')\n",
    "    \n",
    "    numeric_cols = dat[['telecommuting', 'has_company_logo', 'has_questions']]\n",
    "    # func to count words in document\n",
    "    document_word_count = lambda document: len(document.split(' '))\n",
    "    \n",
    "    # count words in column\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    df = copy.deepcopy(dat[columns])\n",
    "    for column in columns:\n",
    "            df[(str(column) + \"_length\")] = dat[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    \n",
    "    \n",
    "    # salary column one hot\n",
    "    category_1 = dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    \n",
    "    salary_1_transform = pd.DataFrame.sparse.from_spmatrix(salary_1_onehot.transform(pd.DataFrame(category_1)))\n",
    "    salary_2_transform = pd.DataFrame.sparse.from_spmatrix(salary_2_onehot.transform(pd.DataFrame(category_2)))\n",
    "    \n",
    "    # transform to one hot\n",
    "    employment_type_transformed =  pd.DataFrame.sparse.from_spmatrix(employment_type_onehot.transform(dat[['employment_type']].fillna('NaN')))\n",
    "    required_experience_transformed =  pd.DataFrame.sparse.from_spmatrix(required_experience_onehot.transform(dat[['required_experience']].fillna('NaN')))\n",
    "    required_education_transformed =  pd.DataFrame.sparse.from_spmatrix(required_education_onehot.transform(dat[['required_education']].fillna('NaN')))\n",
    "    industry_transformed =  pd.DataFrame.sparse.from_spmatrix(industry_onehot.transform(dat[['industry']].fillna('NaN')))\n",
    "    function_transformed =  pd.DataFrame.sparse.from_spmatrix(function_onehot.transform(dat[['function.']].fillna('NaN')))\n",
    "    \n",
    "    \n",
    "    return(pd.concat([nacols,salary_1_transform, salary_2_transform,df.iloc[:,4:],\n",
    "                      employment_type_transformed, required_experience_transformed, required_education_transformed, industry_transformed,function_transformed,numeric_cols],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a29f004",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OneHotEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/09/t5f173_57wj_mzwtx_28y9y80000gn/T/ipykernel_98180/161106240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job_training_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdat_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"practice_job_verification_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fraudulent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/09/t5f173_57wj_mzwtx_28y9y80000gn/T/ipykernel_98180/3095171851.py\u001b[0m in \u001b[0;36mparsing\u001b[0;34m(dat, train_dat)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m### ONE HOT ENCODING (training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0memployment_type_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'employment_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mrequired_experience_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'required_experience'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mrequired_education_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'required_education'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OneHotEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "dat_train = pd.read_csv(\"job_training_data.csv\")\n",
    "dat_train2 = pd.read_csv(\"practice_job_verification_data.csv\")\n",
    "X1 = parsing(dat_train,dat_train)\n",
    "X2 = parsing(dat_train2,dat_train)\n",
    "y1 = dat_train[\"fraudulent\"]\n",
    "y2 = dat_train2[\"fraudulent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_counter(df,columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]):\n",
    "    length = []\n",
    "    for column in columns:\n",
    "        df[(str(column) + \"_length\")] = df[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(\"job_training_data.csv\")\n",
    "jobs = length_counter(jobs)\n",
    "nf_jobs = jobs[jobs[\"fraudulent\"] == 0]\n",
    "f_jobs = jobs[jobs[\"fraudulent\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5331a",
   "metadata": {},
   "source": [
    "# frequency selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d561ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \n",
    "    \".\",\n",
    "    'a',\n",
    " 'about',\n",
    " 'above',\n",
    " 'after',\n",
    " 'again',\n",
    " 'against',\n",
    " 'ain',\n",
    " 'all',\n",
    " 'am',\n",
    " 'an',\n",
    " 'and',\n",
    " 'any',\n",
    " 'are',\n",
    " 'aren',\n",
    " \"aren't\",\n",
    " 'as',\n",
    " 'at',\n",
    " 'be',\n",
    " 'because',\n",
    " 'been',\n",
    " 'before',\n",
    " 'being',\n",
    " 'below',\n",
    " 'between',\n",
    " 'both',\n",
    " 'but',\n",
    " 'by',\n",
    " 'can',\n",
    " 'couldn',\n",
    " \"couldn't\",\n",
    " 'd',\n",
    " 'did',\n",
    " 'didn',\n",
    " \"didn't\",\n",
    " 'do',\n",
    " 'does',\n",
    " 'doesn',\n",
    " \"doesn't\",\n",
    " 'doing',\n",
    " 'don',\n",
    " \"don't\",\n",
    " 'down',\n",
    " 'during',\n",
    " 'each',\n",
    " 'few',\n",
    " 'for',\n",
    " 'from',\n",
    " 'further',\n",
    " 'had',\n",
    " 'hadn',\n",
    " \"hadn't\",\n",
    " 'has',\n",
    " 'hasn',\n",
    " \"hasn't\",\n",
    " 'have',\n",
    " 'haven',\n",
    " \"haven't\",\n",
    " 'having',\n",
    " 'he',\n",
    " 'her',\n",
    " 'here',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'him',\n",
    " 'himself',\n",
    " 'his',\n",
    " 'how',\n",
    " 'i',\n",
    " 'if',\n",
    " 'in',\n",
    " 'into',\n",
    " 'is',\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'it',\n",
    " \"it's\",\n",
    " 'its',\n",
    " 'itself',\n",
    " 'just',\n",
    " 'll',\n",
    " 'm',\n",
    " 'ma',\n",
    " 'me',\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'more',\n",
    " 'most',\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'my',\n",
    " 'myself',\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'now',\n",
    " 'o',\n",
    " 'of',\n",
    " 'off',\n",
    " 'on',\n",
    " 'once',\n",
    " 'only',\n",
    " 'or',\n",
    " 'other',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'out',\n",
    " 'over',\n",
    " 'own',\n",
    " 're',\n",
    " 's',\n",
    " 'same',\n",
    " 'shan',\n",
    " \"shan't\",\n",
    " 'she',\n",
    " \"she's\",\n",
    " 'should',\n",
    " \"should've\",\n",
    " 'shouldn',\n",
    " \"shouldn't\",\n",
    " 'so',\n",
    " 'some',\n",
    " 'such',\n",
    " 't',\n",
    " 'than',\n",
    " 'that',\n",
    " \"that'll\",\n",
    " 'the',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'them',\n",
    " 'themselves',\n",
    " 'then',\n",
    " 'there',\n",
    " 'these',\n",
    " 'they',\n",
    " 'this',\n",
    " 'those',\n",
    " 'through',\n",
    " 'to',\n",
    " 'too',\n",
    " 'under',\n",
    " 'until',\n",
    " 'up',\n",
    " 've',\n",
    " 'very',\n",
    " 'was',\n",
    " 'wasn',\n",
    " \"wasn't\",\n",
    " 'we',\n",
    " 'were',\n",
    " 'weren',\n",
    " \"weren't\",\n",
    " 'what',\n",
    " 'when',\n",
    " 'where',\n",
    " 'which',\n",
    " 'while',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'why',\n",
    " 'will',\n",
    " 'with',\n",
    " 'won',\n",
    " \"won't\",\n",
    " 'wouldn',\n",
    " \"wouldn't\",\n",
    " 'y',\n",
    " 'you',\n",
    " \"you'd\",\n",
    " \"you'll\",\n",
    " \"you're\",\n",
    " \"you've\",\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\"us\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cfeb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strips(x):\n",
    "    return (x.strip().strip(\"'\").strip('\"').strip(\",\").strip(\"(\").strip(\")\").strip(\".\").strip(\";\").strip(\":\"))\n",
    "\n",
    "def merge_and_tokenize(df,column = \"company_profile\",k = 0):\n",
    "    merged_text = []\n",
    "    text_dict = {}\n",
    "    parsed_row = []\n",
    "    for sentence in df[column]:\n",
    "        if sentence == sentence:\n",
    "            words = sentence.lower().split()\n",
    "            words = [strips(w) for w in words if strips(w) not in stop_words]\n",
    "            for word in words: # remove stop words\n",
    "                if \"url\" in str(word):\n",
    "                    words.remove(word)\n",
    "\n",
    "            parsed_row.append(words)\n",
    "            merged_text.extend(words)\n",
    "        else:\n",
    "            parsed_row.append(np.nan)\n",
    "            \n",
    "    fdist = FreqDist(merged_text)\n",
    "    \n",
    "    keys = list(fdist.keys())\n",
    "    \n",
    "    for key in keys:\n",
    "        if fdist[key] <= k:\n",
    "            del fdist[key]\n",
    "    total_counts = sum(fdist.values())\n",
    "    for key in fdist:\n",
    "        fdist[key] = [fdist[key],fdist[key]/total_counts]\n",
    "    return fdist,parsed_row\n",
    "\n",
    "def fraud_frequency(fraud_dict,parsed_rows):\n",
    "    freq_list = []\n",
    "    \n",
    "    for text in tqdm(parsed_rows):\n",
    "        parsed_dict = {key:0 for key in fraud_dict.keys()}\n",
    "        if text == text:\n",
    "            for word in text:\n",
    "                if word in parsed_dict:\n",
    "                    parsed_dict[word] += 1/len(text)\n",
    "        else:\n",
    "            freq_list.append(parsed_dict)\n",
    "            continue\n",
    "        \n",
    "        freq_list.append(parsed_dict)\n",
    "        \n",
    "    return pd.DataFrame(freq_list)\n",
    "\n",
    "def fraud_freq_dictionary(fraud_dict,nfraud_dict, th_percentage = 0.2,tops = 5):\n",
    "    differenced_farud = {}\n",
    "    for key in fraud_dict.keys():\n",
    "        if key in nfraud_dict.keys():\n",
    "            if abs(fraud_dict[key][1] - nfraud_dict[key][1]) >= fraud_dict[key][1]*th_percentage:\n",
    "                differenced_farud[key] = fraud_dict[key]\n",
    "        if key not in nfraud_dict.keys():\n",
    "            differenced_farud[key] = fraud_dict[key]\n",
    "                   \n",
    "    sorted_differenced_fraud = sorted(differenced_farud.items(), key=operator.itemgetter(1),reverse = True)\n",
    "    #out = dict(itertools.islice(sorted_differenced_farud.items(), tops)) \n",
    "    out = dict(sorted_differenced_fraud[:tops])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =merge_and_tokenize(jobs,k =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2de941f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_freq_generator(train,test,column,th_percentage,th_count,tops,train_parsing = True):\n",
    "    if train_parsing:\n",
    "        _,parsed_rows = merge_and_tokenize(train,column,th_count*5)\n",
    "        fraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 1],column ,th_count)\n",
    "        nfraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 0],column ,th_count*5)\n",
    "        filtered_fraud_dict = fraud_freq_dictionary(fraud_dict,nfraud_dict,th_percentage,tops)\n",
    "        fraud_freq = fraud_frequency(filtered_fraud_dict,parsed_rows)\n",
    "    else:\n",
    "        _,parsed_rows = merge_and_tokenize(test,column,th_count*5)\n",
    "        fraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 1],column ,th_count)\n",
    "        nfraud_dict,_ = merge_and_tokenize(train[train[\"fraudulent\"] == 0],column ,th_count*5)\n",
    "        filtered_fraud_dict = fraud_freq_dictionary(fraud_dict,nfraud_dict,th_percentage,tops)\n",
    "        fraud_freq = fraud_frequency(filtered_fraud_dict,parsed_rows)\n",
    "    \n",
    "    return fraud_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50f1f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"job_training_data.csv\")\n",
    "test_data = pd.read_csv(\"job_verification_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eacf8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = length_counter(train_data)\n",
    "test_data = length_counter(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27b1a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len_df = train_data.loc[:,[\"company_profile_length\", \"description_length\",\"requirements_length\",\"benefits_length\"]]\n",
    "test_len_df = test_data.loc[:,[\"company_profile_length\", \"description_length\",\"requirements_length\",\"benefits_length\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0387573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 267777.85it/s]\n",
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 144548.44it/s]\n",
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 254883.02it/s]\n",
      "100%|███████████████████████████████████| 5362/5362 [00:00<00:00, 401232.04it/s]\n"
     ]
    }
   ],
   "source": [
    "company_freq = fraud_freq_generator(train_data,test_data,\"company_profile\",th_percentage = 0.30, th_count = 15, tops = 5)\n",
    "description_freq = fraud_freq_generator(train_data,test_data,\"description\",th_percentage = 0.30, th_count = 15, tops = 10)\n",
    "requirements_freq = fraud_freq_generator(train_data,test_data,\"requirements\",th_percentage = 0.30,th_count = 15, tops = 10)\n",
    "benefits_freq = fraud_freq_generator(train_data,test_data,\"benefits\",th_percentage = 0.30, th_count = 15, tops = 10)\n",
    "\n",
    "big_matrix = pd.concat([company_freq,description_freq,requirements_freq,benefits_freq,train_len_df],axis=1)\n",
    "big_matrix[\"fraudulent\"] = train_data[\"fraudulent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e151f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = big_matrix\n",
    "\n",
    "\n",
    "X = feature_matrix.drop(\"fraudulent\", axis = 1)\n",
    "y = feature_matrix.fraudulent\n",
    "y = y.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state =999999999)\n",
    "rfm = RandomForestClassifier()\n",
    "rfm = RandomForestClassifier(n_estimators = 200, max_features=None ,oob_score=True,n_jobs=6)\n",
    "rfm.fit(X_train,y_train)\n",
    "#y_pred_rfm=rfm.predict(X_test)\n",
    "y_pred_rfm = (rfm.predict_proba(X_test)[:, 1] > 0.15).astype(int)\n",
    "print(confusion_matrix(y_test,y_pred_rfm))\n",
    "print(accuracy_score(y_test,y_pred_rfm))\n",
    "print(recall_score(y_test,y_pred_rfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4c73df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 328732.97it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 183453.79it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 320616.42it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 599786.07it/s]\n"
     ]
    }
   ],
   "source": [
    "company_freq2 = fraud_freq_generator(train_data,test_data,\"company_profile\",th_percentage = 0.30, th_count = 15, tops = 5,train_parsing =False)\n",
    "description_freq2 = fraud_freq_generator(train_data,test_data,\"description\",th_percentage = 0.30, th_count = 15, tops = 5,train_parsing =False)\n",
    "requirements_freq2 = fraud_freq_generator(train_data,test_data,\"requirements\",th_percentage = 0.30,th_count = 15, tops = 5,train_parsing =False)\n",
    "benefits_freq2 = fraud_freq_generator(train_data,test_data,\"benefits\",th_percentage = 0.30, th_count = 15, tops = 5,train_parsing = False)\n",
    "\n",
    "big_matrix2 = pd.concat([company_freq2,description_freq2,requirements_freq2,benefits_freq2,test_len_df],axis=1)\n",
    "big_matrix2[\"fraudulent\"] = test_data[\"fraudulent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da1be603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>candidates</th>\n",
       "      <th>recruiting</th>\n",
       "      <th>bonus</th>\n",
       "      <th>services</th>\n",
       "      <th>work</th>\n",
       "      <th>-</th>\n",
       "      <th>&amp;amp</th>\n",
       "      <th>company</th>\n",
       "      <th>equipment</th>\n",
       "      <th>...</th>\n",
       "      <th>benefits</th>\n",
       "      <th>paid</th>\n",
       "      <th>company</th>\n",
       "      <th>training</th>\n",
       "      <th>-</th>\n",
       "      <th>company_profile_length</th>\n",
       "      <th>description_length</th>\n",
       "      <th>requirements_length</th>\n",
       "      <th>benefits_length</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>829</td>\n",
       "      <td>630</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651</td>\n",
       "      <td>216</td>\n",
       "      <td>295</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2474</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>812</td>\n",
       "      <td>3178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282</td>\n",
       "      <td>845</td>\n",
       "      <td>443</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684</td>\n",
       "      <td>1380</td>\n",
       "      <td>705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>3201</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704</td>\n",
       "      <td>1657</td>\n",
       "      <td>610</td>\n",
       "      <td>627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684</td>\n",
       "      <td>1543</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1232</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     business  candidates  recruiting  bonus  services      work         -  \\\n",
       "0    0.000000         0.0         0.0    0.0  0.000000  0.018519  0.000000   \n",
       "1    0.000000         0.0         0.0    0.0  0.000000  0.000000  0.000000   \n",
       "2    0.000000         0.0         0.0    0.0  0.000000  0.005000  0.000000   \n",
       "3    0.000000         0.0         0.0    0.0  0.000000  0.007018  0.003509   \n",
       "4    0.041667         0.0         0.0    0.0  0.000000  0.000000  0.000000   \n",
       "..        ...         ...         ...    ...       ...       ...       ...   \n",
       "995  0.031250         0.0         0.0    0.0  0.015625  0.000000  0.000000   \n",
       "996  0.000000         0.0         0.0    0.0  0.009901  0.003205  0.003205   \n",
       "997  0.000000         0.0         0.0    0.0  0.000000  0.013158  0.000000   \n",
       "998  0.031250         0.0         0.0    0.0  0.015625  0.000000  0.000000   \n",
       "999  0.000000         0.0         0.0    0.0  0.000000  0.008696  0.000000   \n",
       "\n",
       "         &amp   company  equipment  ...  benefits  paid   company  training  \\\n",
       "0    0.000000  0.018519   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "1    0.000000  0.000000   0.000000  ...  0.000000   0.0  0.000000   0.04878   \n",
       "2    0.000000  0.000000   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "3    0.007018  0.000000   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "4    0.000000  0.000000   0.000000  ...  0.022727   0.0  0.022727   0.00000   \n",
       "..        ...       ...        ...  ...       ...   ...       ...       ...   \n",
       "995  0.008333  0.000000   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "996  0.019231  0.009615   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "997  0.000000  0.000000   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "998  0.000000  0.000000   0.007407  ...  0.000000   0.0  0.000000   0.00000   \n",
       "999  0.000000  0.000000   0.000000  ...  0.000000   0.0  0.000000   0.00000   \n",
       "\n",
       "       -  company_profile_length  description_length  requirements_length  \\\n",
       "0    0.0                     829                 630                   70   \n",
       "1    0.0                     651                 216                  295   \n",
       "2    0.0                       0                2474                    0   \n",
       "3    0.0                     812                3178                    0   \n",
       "4    0.0                     282                 845                  443   \n",
       "..   ...                     ...                 ...                  ...   \n",
       "995  0.0                     684                1380                  705   \n",
       "996  0.0                    1096                3201                  329   \n",
       "997  0.0                     704                1657                  610   \n",
       "998  0.0                     684                1543                  711   \n",
       "999  0.0                       0                1232                   19   \n",
       "\n",
       "     benefits_length  fraudulent  \n",
       "0                 17           0  \n",
       "1                430           0  \n",
       "2                113           0  \n",
       "3                  0           0  \n",
       "4                506           0  \n",
       "..               ...         ...  \n",
       "995                0           0  \n",
       "996                0           0  \n",
       "997              627           0  \n",
       "998                0           0  \n",
       "999               58           1  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49a65cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 24 features, but DecisionTreeClassifier is expecting 39 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/09/t5f173_57wj_mzwtx_28y9y80000gn/T/ipykernel_98180/2635293152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#y_pred_rfm=rfm.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0my_pred_rfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_rfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_rfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    408\u001b[0m                                     reset=False)\n\u001b[1;32m    409\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 24 features, but DecisionTreeClassifier is expecting 39 features as input."
     ]
    }
   ],
   "source": [
    "train_matrix = big_matrix\n",
    "test_matrix = big_matrix2\n",
    "\n",
    "X_train = train_matrix.drop(\"fraudulent\", axis = 1)\n",
    "X_train=(X_train-X_train.mean())/X_train.std()\n",
    "y_train = train_matrix.fraudulent.astype(int)\n",
    "\n",
    "X_test = test_matrix.drop(\"fraudulent\", axis = 1)\n",
    "X_test=(X_test-X_test.mean())/X_test.std()\n",
    "y_test = test_matrix.fraudulent.astype(int)\n",
    "\n",
    "rfm = RandomForestClassifier()\n",
    "rfm = RandomForestClassifier(n_estimators = 200, max_features=None ,oob_score=True,n_jobs=6)\n",
    "rfm.fit(X_train,y_train)\n",
    "#y_pred_rfm=rfm.predict(X_test)\n",
    "y_pred_rfm = (rfm.predict_proba(X_test)[:, 1] > 0.3).astype(int)\n",
    "print(confusion_matrix(y_test,y_pred_rfm))\n",
    "print(accuracy_score(y_test,y_pred_rfm))\n",
    "print(recall_score(y_test,y_pred_rfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcf8de1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>candidates</th>\n",
       "      <th>recruiting</th>\n",
       "      <th>bonus</th>\n",
       "      <th>services</th>\n",
       "      <th>work</th>\n",
       "      <th>-</th>\n",
       "      <th>&amp;amp</th>\n",
       "      <th>company</th>\n",
       "      <th>equipment</th>\n",
       "      <th>...</th>\n",
       "      <th>environment</th>\n",
       "      <th>competitive</th>\n",
       "      <th>time</th>\n",
       "      <th>working</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>company_profile_length</th>\n",
       "      <th>description_length</th>\n",
       "      <th>requirements_length</th>\n",
       "      <th>benefits_length</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2559</td>\n",
       "      <td>871</td>\n",
       "      <td>1383</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>829</td>\n",
       "      <td>391</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>1251</td>\n",
       "      <td>724</td>\n",
       "      <td>805</td>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>829</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>651</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>1099</td>\n",
       "      <td>930</td>\n",
       "      <td>418</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>536</td>\n",
       "      <td>221</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5362 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      business  candidates  recruiting     bonus  services      work  \\\n",
       "0          0.0    0.000000    0.000000  0.000000  0.000000  0.000000   \n",
       "1          0.0    0.000000    0.000000  0.000000  0.000000  0.028571   \n",
       "2          0.0    0.000000    0.000000  0.000000  0.000000  0.031250   \n",
       "3          0.0    0.000000    0.000000  0.000000  0.000000  0.038462   \n",
       "4          0.0    0.000000    0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...         ...         ...       ...       ...       ...   \n",
       "5357       0.0    0.000000    0.000000  0.000000  0.000000  0.019231   \n",
       "5358       0.0    0.000000    0.000000  0.000000  0.000000  0.014286   \n",
       "5359       0.0    0.000000    0.000000  0.000000  0.000000  0.000000   \n",
       "5360       0.0    0.029126    0.029126  0.029126  0.009709  0.024691   \n",
       "5361       0.0    0.000000    0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             -  &amp   company  equipment  ...  environment  competitive  \\\n",
       "0     0.000000   0.0  0.012048        0.0  ...          0.0        0.125   \n",
       "1     0.000000   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "2     0.000000   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "3     0.000000   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "4     0.000000   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "...        ...   ...       ...        ...  ...          ...          ...   \n",
       "5357  0.192308   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "5358  0.000000   0.0  0.014286        0.0  ...          0.0        0.000   \n",
       "5359  0.047619   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "5360  0.000000   0.0  0.012346        0.0  ...          0.0        0.000   \n",
       "5361  0.000000   0.0  0.000000        0.0  ...          0.0        0.000   \n",
       "\n",
       "          time   working  opportunity  company_profile_length  \\\n",
       "0     0.000000  0.000000     0.000000                    2559   \n",
       "1     0.000000  0.000000     0.000000                     829   \n",
       "2     0.000000  0.011050     0.005525                    1251   \n",
       "3     0.000000  0.000000     0.000000                     829   \n",
       "4     0.000000  0.000000     0.000000                       0   \n",
       "...        ...       ...          ...                     ...   \n",
       "5357  0.000000  0.000000     0.000000                       0   \n",
       "5358  0.000000  0.000000     0.000000                       0   \n",
       "5359  0.000000  0.000000     0.000000                       0   \n",
       "5360  0.016304  0.005435     0.005435                    1099   \n",
       "5361  0.000000  0.000000     0.000000                       0   \n",
       "\n",
       "      description_length  requirements_length  benefits_length  fraudulent  \n",
       "0                    871                 1383              100           0  \n",
       "1                    391                   88               16           0  \n",
       "2                    724                  805             2047           0  \n",
       "3                    838                    0                0           0  \n",
       "4                     92                   35               17           0  \n",
       "...                  ...                  ...              ...         ...  \n",
       "5357                 421                  651               10           1  \n",
       "5358                 874                    0                0           1  \n",
       "5359                 336                   35                0           1  \n",
       "5360                 930                  418             2198           1  \n",
       "5361                 536                  221              153           1  \n",
       "\n",
       "[5362 rows x 40 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
