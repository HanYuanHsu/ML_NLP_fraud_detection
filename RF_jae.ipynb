{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d43e30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yunjaecho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk.corpus # sample text for performing tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa5f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(df):\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    one_hot_encoding_columns = ['employment_type', \"required_education\", \"required_experience\",\"function.\", \"industry\"]\n",
    "    length = []\n",
    "    for column in columns:\n",
    "        df[(str(column) + \"_length\")] = df[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    df = pd.get_dummies(df, columns = one_hot_encoding_columns)\n",
    "    return df.iloc[:, 9:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b903cb",
   "metadata": {},
   "source": [
    "# text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a29f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_counter(df,columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]):\n",
    "    length = []\n",
    "    for column in columns:\n",
    "        df[(str(column) + \"_length\")] = df[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e77abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(\"job_training_data.csv\")\n",
    "jobs = length_counter(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ede9d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_jobs = jobs[jobs[\"fraudulent\"] == 0]\n",
    "f_jobs = jobs[jobs[\"fraudulent\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5331a",
   "metadata": {},
   "source": [
    "# frequency selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d561ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \".\",\n",
    "    'a',\n",
    " 'about',\n",
    " 'above',\n",
    " 'after',\n",
    " 'again',\n",
    " 'against',\n",
    " 'ain',\n",
    " 'all',\n",
    " 'am',\n",
    " 'an',\n",
    " 'and',\n",
    " 'any',\n",
    " 'are',\n",
    " 'aren',\n",
    " \"aren't\",\n",
    " 'as',\n",
    " 'at',\n",
    " 'be',\n",
    " 'because',\n",
    " 'been',\n",
    " 'before',\n",
    " 'being',\n",
    " 'below',\n",
    " 'between',\n",
    " 'both',\n",
    " 'but',\n",
    " 'by',\n",
    " 'can',\n",
    " 'couldn',\n",
    " \"couldn't\",\n",
    " 'd',\n",
    " 'did',\n",
    " 'didn',\n",
    " \"didn't\",\n",
    " 'do',\n",
    " 'does',\n",
    " 'doesn',\n",
    " \"doesn't\",\n",
    " 'doing',\n",
    " 'don',\n",
    " \"don't\",\n",
    " 'down',\n",
    " 'during',\n",
    " 'each',\n",
    " 'few',\n",
    " 'for',\n",
    " 'from',\n",
    " 'further',\n",
    " 'had',\n",
    " 'hadn',\n",
    " \"hadn't\",\n",
    " 'has',\n",
    " 'hasn',\n",
    " \"hasn't\",\n",
    " 'have',\n",
    " 'haven',\n",
    " \"haven't\",\n",
    " 'having',\n",
    " 'he',\n",
    " 'her',\n",
    " 'here',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'him',\n",
    " 'himself',\n",
    " 'his',\n",
    " 'how',\n",
    " 'i',\n",
    " 'if',\n",
    " 'in',\n",
    " 'into',\n",
    " 'is',\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'it',\n",
    " \"it's\",\n",
    " 'its',\n",
    " 'itself',\n",
    " 'just',\n",
    " 'll',\n",
    " 'm',\n",
    " 'ma',\n",
    " 'me',\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'more',\n",
    " 'most',\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'my',\n",
    " 'myself',\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'now',\n",
    " 'o',\n",
    " 'of',\n",
    " 'off',\n",
    " 'on',\n",
    " 'once',\n",
    " 'only',\n",
    " 'or',\n",
    " 'other',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'out',\n",
    " 'over',\n",
    " 'own',\n",
    " 're',\n",
    " 's',\n",
    " 'same',\n",
    " 'shan',\n",
    " \"shan't\",\n",
    " 'she',\n",
    " \"she's\",\n",
    " 'should',\n",
    " \"should've\",\n",
    " 'shouldn',\n",
    " \"shouldn't\",\n",
    " 'so',\n",
    " 'some',\n",
    " 'such',\n",
    " 't',\n",
    " 'than',\n",
    " 'that',\n",
    " \"that'll\",\n",
    " 'the',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'them',\n",
    " 'themselves',\n",
    " 'then',\n",
    " 'there',\n",
    " 'these',\n",
    " 'they',\n",
    " 'this',\n",
    " 'those',\n",
    " 'through',\n",
    " 'to',\n",
    " 'too',\n",
    " 'under',\n",
    " 'until',\n",
    " 'up',\n",
    " 've',\n",
    " 'very',\n",
    " 'was',\n",
    " 'wasn',\n",
    " \"wasn't\",\n",
    " 'we',\n",
    " 'were',\n",
    " 'weren',\n",
    " \"weren't\",\n",
    " 'what',\n",
    " 'when',\n",
    " 'where',\n",
    " 'which',\n",
    " 'while',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'why',\n",
    " 'will',\n",
    " 'with',\n",
    " 'won',\n",
    " \"won't\",\n",
    " 'wouldn',\n",
    " \"wouldn't\",\n",
    " 'y',\n",
    " 'you',\n",
    " \"you'd\",\n",
    " \"you'll\",\n",
    " \"you're\",\n",
    " \"you've\",\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\"us\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cfeb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strips(x):\n",
    "    return (x.strip().strip(\"'\").strip('\"').strip(\",\").strip(\"(\").strip(\")\").strip(\".\").strip(\";\").strip(\":\"))\n",
    "\n",
    "def merge_and_tokenize(df,column = \"company_profile\",k = 0):\n",
    "    merged_text = []\n",
    "    text_dict = {}\n",
    "    parsed_row = []\n",
    "    for sentence in df[column]:\n",
    "        if sentence == sentence:\n",
    "            words = sentence.lower().split()\n",
    "            words = [strips(w) for w in words if strips(w) not in stop_words]\n",
    "            for word in words: # remove stop words\n",
    "                if \"url\" in str(word):\n",
    "                    words.remove(word)\n",
    "\n",
    "            parsed_row.append(words)\n",
    "            merged_text.extend(words)\n",
    "        else:\n",
    "            parsed_row.append(np.nan)\n",
    "            \n",
    "    fdist = FreqDist(merged_text)\n",
    "    \n",
    "    keys = list(fdist.keys())\n",
    "    \n",
    "    for key in keys:\n",
    "        if fdist[key] <= k:\n",
    "            del fdist[key]\n",
    "    return fdist,parsed_row\n",
    "\n",
    "def parsed_frequency(freq_dic,parsed_text):\n",
    "    parsed_dict = freq_dic.copy()\n",
    "    freq_list = []\n",
    "    \n",
    "    for text in tqdm(parsed_text):\n",
    "        parsed_dict = freq_dic.copy()\n",
    "        if text == text:\n",
    "            for word in text:\n",
    "                if word in parsed_dict:\n",
    "                    parsed_dict[word] += 1/len(text)\n",
    "        else:\n",
    "            freq_list.append(freq_dic)\n",
    "            continue\n",
    "        \n",
    "        freq_list.append(parsed_dict)\n",
    "        \n",
    "    return freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "85eeaf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'team': 2075, 'work': 2022, 'company': 1988, 'services': 1974, 'people': 1856, 'business': 1513, 'solutions': 1499, 'new': 1419, 'companies': 1265, '&amp': 1240, ...})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_company_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcd16ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'business': 59, 'candidates': 59, 'recruiting': 49, 'bonus': 49, 'services': 48, 'solutions': 47, 'experience': 44, 'products': 41, 'company': 40, 'financing': 40, ...})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_company_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea109d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_company_dict,nf_parsed_company = merge_and_tokenize(nf_jobs,\"company_profile\",2)\n",
    "\n",
    "f_company_dict,f_parsed_company = merge_and_tokenize(f_jobs,\"company_profile\",2)\n",
    "#company_text_freq = parsed_frequency(company_dict,parsed_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_dict,parsed_description = merge_and_tokenize(jobs,\"description\",2)\n",
    "description_text_freq = parsed_frequency(description_dict,parsed_description) # list of freq for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67945d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_dict,parsed_requirements = merge_and_tokenize(jobs,\"requirements\",2)\n",
    "requirements_text_freq = parsed_frequency(requirements_dict,parsed_requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14a4010c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/09/t5f173_57wj_mzwtx_28y9y80000gn/T/ipykernel_87633/1316415592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbenefits_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsed_benefits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"benefits\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbenefits_text_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenefits_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsed_benefits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/09/t5f173_57wj_mzwtx_28y9y80000gn/T/ipykernel_87633/121687291.py\u001b[0m in \u001b[0;36mmerge_and_tokenize\u001b[0;34m(df, column, k)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"url\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mparsed_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "benefits_dict,parsed_benefits = merge_and_tokenize(jobs,\"benefits\",2)\n",
    "benefits_text_freq = parsed_frequency(benefits_dict,parsed_benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91477e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [\"a\",\"a\",\"b\"]\n",
    "s.remove(\"a\")\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
