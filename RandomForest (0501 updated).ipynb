{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4086ef8e",
   "metadata": {},
   "source": [
    "Clean Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8287eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library needed\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c553f",
   "metadata": {},
   "source": [
    "# Code to deal with salary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86006978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if character is in text\n",
    "def alpha_in_text(text):\n",
    "    return(any(c.isalpha() for c in text))\n",
    "\n",
    "# see how many dashes are in text\n",
    "def number_of_dashes(text):\n",
    "    return(sum([1 for i in text if '-' in i]))\n",
    "\n",
    "# extract smallest salary range value\n",
    "def salary_extract_first(text):\n",
    "    \n",
    "    if pd.isna(text) is True:\n",
    "        return(-1)\n",
    "    \n",
    "    elif alpha_in_text(text) is True:\n",
    "        return(-2)\n",
    "    \n",
    "    elif '-' in text:\n",
    "        if number_of_dashes(text) == 1:\n",
    "            if re.split('-',text)[0].isdigit() is True:\n",
    "                return(float(re.split('-',text)[0]))\n",
    "            else:\n",
    "                return(-1)\n",
    "            \n",
    "        else:\n",
    "            return(-1)\n",
    "    else:\n",
    "        return(-1)\n",
    "    \n",
    "# largest salary range value\n",
    "def salary_extract_second(text):\n",
    "    \n",
    "    if pd.isna(text) is True:\n",
    "        return(-1)\n",
    "    \n",
    "    elif alpha_in_text(text) is True:\n",
    "        return(-2)\n",
    "    \n",
    "    elif '-' in text:\n",
    "        if number_of_dashes(text) == 1:\n",
    "            if re.split('-',text)[1].isdigit() is True:\n",
    "                return(float(re.split('-',text)[1]))\n",
    "            else:\n",
    "                return(-1)\n",
    "            \n",
    "        else:\n",
    "            return(-1)\n",
    "    else:\n",
    "        return(-1)\n",
    "\n",
    "# convert numeric salary to category\n",
    "def salary_category_first(number):\n",
    "    percentile = [60.0, 14000.0, 20000.0, 30000.0, 35000.0, 44374.4, 55000.0, 70000.0, 90000.0]\n",
    "    if number == -1:\n",
    "        return(str(1))\n",
    "    \n",
    "    if number == -2:\n",
    "        return(str(2))\n",
    "    \n",
    "    for i in range(len(percentile)):\n",
    "        if i not in {0,8}:\n",
    "            if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                return(str(i+3))\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        if i == 0:\n",
    "            if number < percentile[0]:\n",
    "                return(str(i+3))\n",
    "        if i == 8:\n",
    "            if number >= percentile[8]:\n",
    "                return(str(i+3))\n",
    "            \n",
    "\n",
    "\n",
    "def salary_category_second(number):\n",
    "    percentile = [120, 20000.0, 30000.0, 40000.0, 50000.0, 65000.0, 80000.0, 100000.0, 130000.0]\n",
    "    if number == -1:\n",
    "        return(str(1))\n",
    "    \n",
    "    if number == -2:\n",
    "        return(str(2))\n",
    "    \n",
    "    for i in range(len(percentile)):\n",
    "        if i not in {0,8}:\n",
    "            if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                return(str(i+3))\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        if i == 0:\n",
    "            if number < percentile[0]:\n",
    "                return(str(i+3))\n",
    "        if i == 8:\n",
    "            if number >= percentile[8]:\n",
    "                return(str(i+3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a08c22",
   "metadata": {},
   "source": [
    "# Read Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33488660",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"job_training_data.csv\")\n",
    "stop_words = {'a', 'the', 'of', 'in', 'for'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7a129",
   "metadata": {},
   "source": [
    "# Models to train on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0847c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words).fit(dat[['company_profile','description','requirements','benefits']].fillna('NaN').agg(' '.join,axis=1))\n",
    "# one hot encoding\n",
    "employment_type_onehot = OneHotEncoder(handle_unknown='ignore').fit(dat[['employment_type']].fillna('NaN'))\n",
    "required_experience_onehot = OneHotEncoder(handle_unknown='ignore').fit(dat[['required_experience']].fillna('NaN'))\n",
    "required_education_onehot = OneHotEncoder(handle_unknown='ignore').fit(dat[['required_education']].fillna('NaN'))\n",
    "industry_onehot = OneHotEncoder(handle_unknown='ignore').fit(dat[['industry']].fillna('NaN'))\n",
    "function_onehot = OneHotEncoder(handle_unknown='ignore').fit(dat[['function.']].fillna('NaN'))\n",
    "category_1 = dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "category_2 = dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "salary_1_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_1))\n",
    "salary_2_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4912ae",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d558cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(dat,stop_words):\n",
    "    \n",
    "    nacols = dat.isna()[['title', 'location', 'department', 'salary_range','description', 'requirements', 'benefits',\n",
    "                      'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
    "                      'required_experience', 'required_education', 'industry', 'function.']].astype('int')\n",
    "    \n",
    "    numeric_cols = dat[['telecommuting', 'has_company_logo', 'has_questions']]\n",
    "    # func to count words in document\n",
    "    document_word_count = lambda document: len(document.split(' '))\n",
    "    \n",
    "    # count words in column\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    df = copy.deepcopy(dat[columns])\n",
    "    for column in columns:\n",
    "            df[(str(column) + \"_length\")] = dat[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    \n",
    "    \n",
    "    # salary column one hot\n",
    "    category_1 = dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    \n",
    "    salary_1_transform = pd.DataFrame.sparse.from_spmatrix(salary_1_onehot.transform(pd.DataFrame(category_1)))\n",
    "    salary_2_transform = pd.DataFrame.sparse.from_spmatrix(salary_2_onehot.transform(pd.DataFrame(category_2)))\n",
    "    \n",
    "    # transform to one hot\n",
    "    employment_type_transformed =  pd.DataFrame.sparse.from_spmatrix(employment_type_onehot.transform(dat[['employment_type']].fillna('NaN')))\n",
    "    required_experience_transformed =  pd.DataFrame.sparse.from_spmatrix(required_experience_onehot.transform(dat[['required_experience']].fillna('NaN')))\n",
    "    required_education_transformed =  pd.DataFrame.sparse.from_spmatrix(required_education_onehot.transform(dat[['required_education']].fillna('NaN')))\n",
    "    industry_transformed =  pd.DataFrame.sparse.from_spmatrix(industry_onehot.transform(dat[['industry']].fillna('NaN')))\n",
    "    function_transformed =  pd.DataFrame.sparse.from_spmatrix(function_onehot.transform(dat[['function.']].fillna('NaN')))\n",
    "    \n",
    "    \n",
    "    return(pd.concat([nacols,salary_1_transform, salary_2_transform,df.iloc[:,4:],\n",
    "                      employment_type_transformed, required_experience_transformed, required_education_transformed, industry_transformed,function_transformed,numeric_cols],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1db7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'a', 'the', 'of', 'in', 'for'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db313eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"job_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64128c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parsing(dat,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d8c5b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1535,    8],\n",
       "       [  33,   33]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "y = dat.fraudulent\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators = 200,max_features=None ,n_jobs=6)\n",
    "rf.fit(X_train,y_train)\n",
    "sklearn.metrics.confusion_matrix(y_test,rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05873dd",
   "metadata": {},
   "source": [
    "# Original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e37659f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1538,    5],\n",
       "       [  36,   30]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def parsing1(df):\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    one_hot_encoding_columns = ['employment_type', \"required_education\", \"required_experience\",\"function.\", \"industry\"]\n",
    "    length = []\n",
    "    for column in columns:\n",
    "        df[(str(column) + \"_length\")] = df[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    df = pd.get_dummies(df, columns = one_hot_encoding_columns)\n",
    "    return df.iloc[:, 9:]\n",
    "\n",
    "jobs = pd.read_csv(\"job_training_data.csv\")\n",
    "jobs = parsing1(jobs)\n",
    "feature_matrix = jobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "feature_matrix = jobs\n",
    "X = feature_matrix.drop(\"fraudulent\", axis = 1)\n",
    "y = feature_matrix.fraudulent\n",
    "y = y.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "rfm = RandomForestClassifier()\n",
    "rfm= RandomForestClassifier(n_estimators = 200 ,oob_score=True, n_jobs=6)\n",
    "rfm.fit(X_train,y_train)\n",
    "rfm.score(X_train,y_train)\n",
    "y_pred_rfm=rfm.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred_rfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80182a7",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = preprocessing.scale(feature_matrix,with_mean=True,with_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8782d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(data_normalized)\n",
    "components = pca.components_[0:np.where(pca.explained_variance_ratio_.cumsum() > 0.9)[0][0]+1,:]\n",
    "pca_features = np.matmul(data_normalized,np.transpose(components))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac7c32",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_matrix\n",
    "y = dat.fraudulent\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42)\n",
    "rfm = RandomForestClassifier(n_estimators = 200,n_jobs=6)\n",
    "rfm.fit(X_train,y_train)\n",
    "y_pred_rfm=rfm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ec17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test,y_pred_rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c027f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
